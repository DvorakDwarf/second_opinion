{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3674ae17",
   "metadata": {},
   "source": [
    "## Second Opinion model practice on MNIST\n",
    "\n",
    "Hello and welcome to my TED talk. This notebook is about an idea for architecture I got when learning DL. I am oblivious to how effective it is or even if I'm original. The idea sounds similar to MoE (Mixture of Experts). While MoE seems to be about seperating unique tasks between a couple models, my idea is to take MNIST and make 10 models that each are only responsible for their own number and nothing else. The idea is that they would be easier to tweak individually and theoretically improve accuracy. \\\n",
    "I also realised that this can be an Evangelion reference if you squint at it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686e6bf",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "But first we need to initialize the victim of many amateur machine learning students - MNIST, a dataset of tens of thousands of pictures of handwritten digits that we will use to teach our \"\"\"experts\"\"\" how to recognize numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3991cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "DATA_WORKERS = 0\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def get_loaders(target_transform=None):\n",
    "    #No data augmentation necessary. It's literally just 28x28 pixels\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    train_data = datasets.MNIST(root='data', \n",
    "                                train=True,\n",
    "                                download=True, \n",
    "                                transform=transform,\n",
    "                                target_transform=target_transform)\n",
    "    #Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_workers=DATA_WORKERS,\n",
    "                                            shuffle=True)\n",
    "\n",
    "    val_data = datasets.MNIST(root='data', \n",
    "                                train=False,\n",
    "                                download=True, \n",
    "                                transform=transform,\n",
    "                                target_transform=target_transform)\n",
    "    #Data loader\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_workers=DATA_WORKERS)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = get_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0383",
   "metadata": {},
   "source": [
    "Now let's take a look at what we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "image_batch, labels = next(data_iter)\n",
    "image_batch = image_batch.numpy()\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(7,7), nrows=3, ncols=3, sharey=True, sharex=True)\n",
    "for ax, img in zip(axes.flatten(), image_batch):\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63036faf",
   "metadata": {},
   "source": [
    "If you spent any amount of time trying to do image classification these numbers better be burned in your mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8e514",
   "metadata": {},
   "source": [
    "# The Fun Stuffâ„¢\n",
    "\n",
    "Now we can get to architecture. For this particular experiment I will be going back to the good ol' days of dense(fully connected) layers. I'm not trying to get state of the art performance here so it's nice to not have to overthink things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3a53f",
   "metadata": {},
   "source": [
    "# The Baseline \n",
    "\n",
    "We will begin with creating a regular fully connected classifier for MNIST and see how it performs. We will use this as the baseline on which to judge the second opinion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d92472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Solo_Expert(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Solo_Expert, self).__init__()\n",
    "        \n",
    "        # define hidden linear layers\n",
    "        self.fc1 = nn.Linear(28*28, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2, hidden_dim*4)\n",
    "        \n",
    "        # final fully-connected layer\n",
    "        self.fc4 = nn.Linear(hidden_dim*4, 10)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # all hidden layers\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        # final layer with tanh applied\n",
    "        out = F.tanh(self.fc4(x))\n",
    "\n",
    "        return out\n",
    "    \n",
    "#Check what device to use\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "print(f\"Device is {device}\")\n",
    "\n",
    "HIDDEN_DIM = 32\n",
    "solo_model = Solo_Expert(HIDDEN_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5accfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm \n",
    "import datetime\n",
    "\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.0001\n",
    "target = \"full\"\n",
    "\n",
    "optimizer = optim.SGD(solo_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "def training_loop(model, target, train_loader, val_loader):\n",
    "    beginning = datetime.datetime.now()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        total_loss = 0.0\n",
    "        total_val_loss = 0.0\n",
    "        best_loss = 9999\n",
    "        \n",
    "        #Train\n",
    "        for (imgs, labels) in tqdm(train_loader, desc=\"Training\"):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            out = solo_model(imgs)\n",
    "            loss = loss_fn(out, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        #Validate\n",
    "        for (val_imgs, val_labels) in tqdm(val_loader, desc=\"Validation\"):\n",
    "            val_imgs = val_imgs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            model.train(True)\n",
    "\n",
    "            val_out = model(val_imgs)\n",
    "            val_loss = loss_fn(val_out, val_labels)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        epoch_val_loss = total_val_loss / len(val_loader)\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "            \n",
    "        if epoch_val_loss < best_loss:\n",
    "            best_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), \"data/\" + f\"MNIST_[{beginning}].pth\")\n",
    "\n",
    "        # if epoch == 1 or epoch % 10 == 0:\n",
    "        now = datetime.datetime.now()\n",
    "        print(f\"{now}\\nEpoch {epoch}\\ntr_loss {epoch_loss:.5}\\nval_loss {epoch_val_loss:.5}\\n\")\n",
    "\n",
    "training_loop(solo_model, target, train_loader, val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aba99295",
   "metadata": {},
   "source": [
    "And now to test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_model.load_state_dict(torch.load(f\"data/MNIST{target}_[2023-05-19 08:57:46.752214].pth\"))\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    for name, loader in [(\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(solo_model, val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f9f6ab",
   "metadata": {},
   "source": [
    "An 86-89% accuracy might not be the knife's edge in terms of classification but it's a fair start (for a dense network)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7b6412",
   "metadata": {},
   "source": [
    "# Second Opinion\n",
    "\n",
    "Now that we have seen the performance of the baseline, we can compare it to a small horde of single-minded models. A layer has been removed from these models because trying to classify whether something is 7 or not should not require as many parameters as distinguishing between all 10 numbers. We will start by changing the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68981ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLOW ?\n",
    "def relabel(labels, target):\n",
    "    for label in labels:\n",
    "        if label == target:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "target_transform = transforms.Lambda(relabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "814e5552",
   "metadata": {},
   "source": [
    "And we will make a simplified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, hidden_dim*2)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 2)\n",
    "        \n",
    "        #Overfitting be damned\n",
    "        self.dropout = nn.Dropout(0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
